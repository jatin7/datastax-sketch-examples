{"paragraphs":[{"text":"%md\n# HyperLogLog\n\nHyperloglog addresses the problem in determining cardinality on large datasets. Usefull for efficiantly summerizing streams of data such as number of unique visitors of a website or counting ad impressions.\n\n","dateUpdated":"2018-04-03T02:37:41+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>HyperLogLog</h1>\n<p>Hyperloglog addresses the problem in determining cardinality on large datasets. Usefull for efficiantly summerizing streams of data such as number of unique visitors of a website or counting ad impressions.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1522723061392_1504240150","id":"20171029-215631_784415406","dateCreated":"2018-04-03T02:37:41+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1054"},{"title":"Add Spark Dependencies","text":"%dep\n\n//Execute before other paragraphs\n//Add these dependencies to the interpreter to make your life easier...\n\nz.reset()\nz.load(\"com.twitter:algebird-core_2.11:0.13.3\")\nz.load(\"org.apache.bahir:spark-streaming-twitter_2.10:2.1.0\")\n","dateUpdated":"2018-04-03T02:37:41+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1522723061393_1503855402","id":"20171029-223254_15426998","dateCreated":"2018-04-03T02:37:41+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1055"},{"title":"Create Keyspace","text":"%cassandra\n\nCREATE KEYSPACE IF NOT EXISTS approximations WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 };","dateUpdated":"2018-04-03T02:37:41+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/undefined","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1522723061394_1505009648","id":"20171029-192552_1819477421","dateCreated":"2018-04-03T02:37:41+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1056"},{"title":"Create Table","text":"%cassandra\n\nCREATE TABLE IF NOT EXISTS approximations.hlldata ( id text, date text, batchtime timestamp, batchwindow int, totalinwindow int, uniqueperbatch int, hllstore blob, PRIMARY KEY ((id, date), batchTime));\n","dateUpdated":"2018-04-03T02:37:41+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/undefined","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1522723061394_1505009648","id":"20171024-182121_1460140069","dateCreated":"2018-04-03T02:37:41+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1057"},{"title":"Create Search Index for Timeseries","text":"%cassandra\n\nCREATE SEARCH  INDEX IF NOT EXISTS ON approximations.hlldata WITH COLUMNS batchtime, uniqueperbatch;\n","dateUpdated":"2018-04-03T02:37:41+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/undefined","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1522723061395_1504624899","id":"20171102-144256_1684484170","dateCreated":"2018-04-03T02:37:41+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1058"},{"title":"Approximate Unique Twitter Users from Live Stream","text":"%spark\n\n//Listen to twitter stream and count unique users\n\nimport com.twitter.algebird.HyperLogLog._\nimport com.twitter.algebird.HyperLogLogMonoid\nimport org.apache.log4j.{Level, Logger}\n\nimport org.apache.spark.SparkConf\nimport org.apache.spark.storage.StorageLevel\nimport org.apache.spark.streaming.{Seconds, StreamingContext}\nimport org.apache.spark.streaming.twitter._\nimport twitter4j.conf.ConfigurationBuilder\nimport twitter4j.auth.OAuthAuthorization\nimport java.util.Date\nimport java.text.SimpleDateFormat\nimport com.datastax.spark.connector.streaming._\nimport com.datastax.spark.connector._\nimport com.datastax.spark.connector.SomeColumns\n\n/**\n * Example of using HyperLogLog monoid from Twitter's Algebird together with Spark Streaming's\n * TwitterInputDStream\n */\n\n    /** Bit size parameter for HyperLogLog, trades off accuracy vs size */\n    val BIT_SIZE = 12\n    \n    //Size of window in Stream Processing\n    val WINDOW_SIZE = 10\n    val minutesToStream = 10;\n    \n    val filters = new Array[String](0)\n    \n    //BYO Credentials\n    val cb = new ConfigurationBuilder();\n    cb.setDebugEnabled(true)\n      .setOAuthConsumerKey(\"****\")\n      .setOAuthConsumerSecret(\"****\")\n      .setOAuthAccessToken(\"****\")\n      .setOAuthAccessTokenSecret(\"****\")\n  \n   \n    val auth = new OAuthAuthorization(cb.build)\n    \n    val ssc = new StreamingContext(sc, Seconds(WINDOW_SIZE))\n    \n    val stream = TwitterUtils.createStream(ssc, Some(auth), filters, StorageLevel.MEMORY_ONLY_SER)\n\n    val users = stream.map(status => status.getUser.getId)\n\n    val hll = new HyperLogLogMonoid(BIT_SIZE)\n    \n    val approxUsers = users.mapPartitions(ids => {\n      ids.map(id => hll.create(id))\n    }).reduce(_ + _)\n\n    val todayAsString = new SimpleDateFormat(\"MM-dd-yyyy\").format(new Date())\n   \n    approxUsers.foreachRDD(rdd => {\n      val totalInWindow = rdd.count();\n      if (totalInWindow != 0) {\n       \n        val now = new Date();\n       \n        val partial = rdd.first()\n       \n        val uniqueperbatch = partial.estimatedSize.toInt\n        \n        println(\"Approx distinct users this batch: %d\".format(uniqueperbatch))\n        \n        val oneWindowValue = sc.parallelize(Seq((\"uniqueusers\", todayAsString, now, WINDOW_SIZE, totalInWindow, uniqueperbatch, toBytes(partial))))\n       \n        oneWindowValue.saveToCassandra(\"approximations\", \"hlldata\", SomeColumns(\"id\", \"date\", \"batchtime\", \"batchwindow\", \"totalinwindow\", \"uniqueperbatch\", \"hllstore\"))\n\n      }\n    })\n\n\n    ssc.start()\n    ssc.awaitTerminationOrTimeout(minutesToStream * 60  * 1000)//2 minutes...\n    ssc.stop(stopSparkContext = false, stopGracefully=true)\n    \n","dateUpdated":"2018-04-03T02:37:41+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{"0":{"graph":{"mode":"table","height":1656,"optionOpen":false}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1522723061396_1502701155","id":"20171024-141946_1818057078","dateCreated":"2018-04-03T02:37:41+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1059"},{"title":"Approximate Unique Twitter Users by Aggregating Window Approximations","text":"%spark\n\n//Aggregate Hyperloglog sketch data into single Hyperloglog structure\n\nimport com.datastax.spark.connector.streaming._\nimport com.datastax.spark.connector._\nimport com.datastax.spark.connector.SomeColumns\nimport com.datastax.spark.connector.rdd._\nimport org.apache.spark.SparkContext    \nimport org.apache.spark.SparkContext._\nimport org.apache.spark.SparkConf\nimport org.apache.spark.storage.StorageLevel\nimport org.apache.spark.streaming.{Seconds, StreamingContext}\n\nimport com.twitter.algebird.HyperLogLog._\nimport com.twitter.algebird.HyperLogLogMonoid\nimport org.apache.log4j.{Level, Logger}\nimport com.twitter.algebird.HLL\nimport java.util.Date\nimport java.text.SimpleDateFormat\n\nval todayAsString = new SimpleDateFormat(\"MM-dd-yyyy\").format(new Date())\n   \nval rdd  = sc.cassandraTable[Array[Byte]](\"approximations\", \"hlldata\")\n              .select(\"hllstore\")\n              .where(\"id = ?\", \"uniqueusers\").where(\"date = ?\", todayAsString)\n\nval approxUsers = rdd.mapPartitions(ids => {\n  ids.map(id => fromBytes(id))\n}).reduce(_ + _)\n\nval hllagg = approxUsers.estimatedSize.toInt\n\nprintln(\"Total For HLL:\"+hllagg)\n\n","dateUpdated":"2018-04-03T02:37:41+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1522723061397_1502316406","id":"20171026-155753_802562419","dateCreated":"2018-04-03T02:37:41+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1060"},{"title":"Create Table to Store Aggregate Results","text":"%cassandra\n\nCREATE TABLE IF NOT EXISTS approximations.hlldataaggregate ( id text, date text, batchtime timestamp, batchwindow int, totalinwindow int, uniqueperbatch int, hllstore blob, PRIMARY KEY ((id, date), batchTime));\n\n","dateUpdated":"2018-04-03T02:37:41+0000","config":{"editorSetting":{"language":"text","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/undefined","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1522723061397_1502316406","id":"20180127-203330_908535097","dateCreated":"2018-04-03T02:37:41+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1061"},{"title":"Create Search Index For Aggregate Results","text":"%cassandra\n\nCREATE SEARCH INDEX IF NOT EXISTS ON approximations.hlldataaggregate WITH COLUMNS id, date, batchtime, uniqueperbatch;\n\n\n","dateUpdated":"2018-04-03T02:37:41+0000","config":{"editorSetting":{"language":"text","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/undefined","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1522723061398_1503470653","id":"20180127-172012_932976666","dateCreated":"2018-04-03T02:37:41+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1062"},{"title":"Store Aggregate Results","text":"%spark\n\n//Aggregate Results and Store to rollup window\n\nimport com.datastax.spark.connector.streaming._\nimport com.datastax.spark.connector._\nimport com.datastax.spark.connector.SomeColumns\nimport com.datastax.spark.connector.rdd._\nimport org.apache.spark.SparkContext    \nimport org.apache.spark.SparkContext._\nimport org.apache.spark.SparkConf\nimport org.apache.spark.storage.StorageLevel\nimport org.apache.spark.streaming.{Seconds, StreamingContext}\n\nimport com.twitter.algebird.HyperLogLog._\nimport com.twitter.algebird.HyperLogLogMonoid\nimport org.apache.log4j.{Level, Logger}\nimport com.twitter.algebird.HLL\nimport java.util.Date\nimport java.text.SimpleDateFormat\n\nval todayAsString = new SimpleDateFormat(\"MM-dd-yyyy\").format(new Date())\n   \nval rdd  = sc.cassandraTable[Array[Byte]](\"approximations\", \"hlldata\")\n              .select(\"hllstore\")\n              .where(\"id = ?\", \"uniqueusers\").where(\"date = ?\", todayAsString).where(\"batchtime > ?\", new Date(System.currentTimeMillis() - (30 * 60 * 1000)))\n\nval approxUsers = rdd.mapPartitions(ids => {\n  ids.map(id => fromBytes(id))\n}).reduce(_ + _)\n\nval hllagg = approxUsers.estimatedSize.toInt\n\nval oneWindowValue = sc.parallelize(Seq((\"uniqueusers\", todayAsString, new Date(), 0, 1, hllagg, toBytes(approxUsers))))\n\nprintln(\"Total For HLL:\"+hllagg)\n\n//oneWindowValue.saveToCassandra(\"approximations\", \"hlldataaggregate\", SomeColumns(\"id\", \"date\", \"batchtime\", \"batchwindow\", \"totalinwindow\", \"uniqueperbatch\", \"hllstore\"))\n        \n","dateUpdated":"2018-04-03T02:37:41+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1522723061398_1503470653","id":"20180127-173612_983486301","dateCreated":"2018-04-03T02:37:41+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1063"},{"text":"%cassandra\n\nSELECT * FROM approximations.hlldata WHERE id = 'uniqueusers' ALLOW FILTERING;","dateUpdated":"2018-04-03T02:37:41+0000","config":{"colWidth":12,"editorMode":"ace/mode/undefined","results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"lineChart":{},"stackedAreaChart":{"style":"stack"},"multiBarChart":{}},"commonSetting":{},"keys":[{"name":"batchtime","index":2,"aggr":"sum"},{"name":"id","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"uniqueperbatch","index":6,"aggr":"sum"}]},"helium":{}}},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1522723061399_1503085904","id":"20171024-193717_1816755798","dateCreated":"2018-04-03T02:37:41+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1064"},{"dateUpdated":"2018-04-03T02:37:41+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1522723061399_1503085904","id":"20171024-144008_2052649078","dateCreated":"2018-04-03T02:37:41+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1065"}],"name":"DataStax Sketches/HyperLogLog","id":"2DD45HRHJ","angularObjects":{"2DB65Y49W:shared_process":[],"2D9SZQ2Q3:shared_process":[],"2DA3P6XY2:shared_process":[],"2DCN64GS2:shared_process":[],"2DA2526KY:shared_process":[],"2DBTYKG7X:shared_process":[],"2D9WM939D:shared_process":[],"2DBAVC4NY:shared_process":[],"2D9N2JJAW:shared_process":[],"2DCAQXCTE:shared_process":[],"2DARD18E3:shared_process":[],"2DCA515RH:shared_process":[],"2DAYWWA24:shared_process":[],"2D9ARXMWB:shared_process":[],"2DC8SJRAD:shared_process":[],"2DBNPAWM8:shared_process":[],"2D9R7YWJB:shared_process":[],"2DAP2E4C9:shared_process":[],"2DC294HQS:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}