{
  "paragraphs": [
    {
      "text": "%md\n# HyperLogLog\n\nHyperloglog addresses the problem in determining cardinality on large datasets. Usefull for efficiantly summerizing streams of data such as number of unique visitors of a website or counting ad impressions.\n\n",
      "user": "anonymous",
      "dateUpdated": "Nov 8, 2017 5:05:05 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eHyperLogLog\u003c/h1\u003e\n\u003cp\u003eHyperloglog addresses the problem in determining cardinality on large datasets. Usefull for efficiantly summerizing streams of data such as number of unique visitors of a website or counting ad impressions.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1509328591687_-1932585205",
      "id": "20171029-215631_784415406",
      "dateCreated": "Oct 29, 2017 9:56:31 PM",
      "dateStarted": "Nov 8, 2017 5:05:05 PM",
      "dateFinished": "Nov 8, 2017 5:05:05 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Add Spark Dependencies",
      "text": "%dep\n\n//Add these dependencies to the interpreter to make your life easier...\n\nz.reset()\nz.load(\"com.twitter:algebird-core_2.11:0.13.3\")\nz.load(\"org.apache.bahir:spark-streaming-twitter_2.10:2.1.0\")\n",
      "user": "anonymous",
      "dateUpdated": "Oct 30, 2017 10:18:52 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1509330774905_-706528084",
      "id": "20171029-223254_15426998",
      "dateCreated": "Oct 29, 2017 10:32:54 PM",
      "dateStarted": "Oct 30, 2017 10:18:52 PM",
      "dateFinished": "Oct 30, 2017 10:18:57 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Create Keyspace",
      "text": "%cassandra\n\nCREATE KEYSPACE IF NOT EXISTS approximations WITH REPLICATION \u003d { \u0027class\u0027 : \u0027SimpleStrategy\u0027, \u0027replication_factor\u0027 : 1 };",
      "user": "anonymous",
      "dateUpdated": "Oct 29, 2017 10:16:25 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/undefined",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1509319552381_380422920",
      "id": "20171029-192552_1819477421",
      "dateCreated": "Oct 29, 2017 7:25:52 PM",
      "dateStarted": "Oct 29, 2017 10:16:25 PM",
      "dateFinished": "Oct 29, 2017 10:16:25 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Create Table",
      "text": "%cassandra\n\nCREATE TABLE IF NOT EXISTS approximations.hlldata ( id text, date text, batchtime timestamp, batchwindow int, totalinwindow int, uniqueperbatch int, hllstore blob, PRIMARY KEY ((id, date), batchTime));\n",
      "user": "anonymous",
      "dateUpdated": "Oct 29, 2017 10:16:28 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/undefined",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508883681568_-609384909",
      "id": "20171024-182121_1460140069",
      "dateCreated": "Oct 24, 2017 6:21:21 PM",
      "dateStarted": "Oct 29, 2017 10:16:28 PM",
      "dateFinished": "Oct 29, 2017 10:16:28 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Create Search Index for Timeseries",
      "text": "%cassandra\n\nCREATE SEARCH  INDEX IF NOT EXISTS ON approximations.hlldata WITH COLUMNS batchtime;\n",
      "user": "anonymous",
      "dateUpdated": "Nov 6, 2017 4:30:21 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/undefined",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1509648176309_952768016",
      "id": "20171102-144256_1684484170",
      "dateCreated": "Nov 2, 2017 2:42:56 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n\nimport com.twitter.algebird.HyperLogLog._\nimport com.twitter.algebird.HyperLogLogMonoid\nimport org.apache.log4j.{Level, Logger}\n\nimport org.apache.spark.SparkConf\nimport org.apache.spark.storage.StorageLevel\nimport org.apache.spark.streaming.{Seconds, StreamingContext}\nimport org.apache.spark.streaming.twitter._\nimport twitter4j.conf.ConfigurationBuilder\nimport twitter4j.auth.OAuthAuthorization\nimport java.util.Date\nimport java.text.SimpleDateFormat\nimport com.datastax.spark.connector.streaming._\nimport com.datastax.spark.connector._\nimport com.datastax.spark.connector.SomeColumns\n\n/**\n * Example of using HyperLogLog monoid from Twitter\u0027s Algebird together with Spark Streaming\u0027s\n * TwitterInputDStream\n */\n\n    /** Bit size parameter for HyperLogLog, trades off accuracy vs size */\n    val BIT_SIZE \u003d 12\n    \n    //Size of window in Stream Processing\n    val WINDOW_SIZE \u003d 10\n    val minutesToStream \u003d 10;\n    \n    val filters \u003d new Array[String](0)\n    \n    //BYO Credentials\n    val cb \u003d new ConfigurationBuilder();\n    cb.setDebugEnabled(true)\n      .setOAuthConsumerKey(\"7foJQWMfxU9p6K70M0o716fFX\")\n      .setOAuthConsumerSecret(\"nGz5WyotqFtgKad928lWPHJBTPl0DH7StKaRAQqnkcYbcnzMGx\")\n      .setOAuthAccessToken(\"58465931-FBUb5th1TNcq1FwNopqy5WxLeV9zT845hSpGFPq9C\")\n      .setOAuthAccessTokenSecret(\"kGB1aGMWDwZKRxOx8QEmO2S0wB6x3RzV07hor3FIxVKkl\")\n  \n   \n    val auth \u003d new OAuthAuthorization(cb.build)\n    \n    val ssc \u003d new StreamingContext(sc, Seconds(WINDOW_SIZE))\n    \n    val stream \u003d TwitterUtils.createStream(ssc, Some(auth), filters, StorageLevel.MEMORY_ONLY_SER)\n\n    val users \u003d stream.map(status \u003d\u003e status.getUser.getId)\n\n    val hll \u003d new HyperLogLogMonoid(BIT_SIZE)\n    \n    val approxUsers \u003d users.mapPartitions(ids \u003d\u003e {\n      ids.map(id \u003d\u003e hll.create(id))\n    }).reduce(_ + _)\n\n    val todayAsString \u003d new SimpleDateFormat(\"MM-dd-yyyy\").format(new Date())\n   \n    approxUsers.foreachRDD(rdd \u003d\u003e {\n      val totalInWindow \u003d rdd.count();\n      if (totalInWindow !\u003d 0) {\n       \n        val now \u003d new Date();\n       \n        val partial \u003d rdd.first()\n       \n        val uniqueperbatch \u003d partial.estimatedSize.toInt\n        \n       // println(\"Total entries in this batch: %d\".format(totalInWindow))\n        println(\"Approx distinct users this batch: %d\".format(uniqueperbatch))\n        \n        val oneWindowValue \u003d sc.parallelize(Seq((\"tweets\", todayAsString, now, WINDOW_SIZE, totalInWindow, uniqueperbatch, toBytes(partial))))\n       \n        oneWindowValue.saveToCassandra(\"approximations\", \"hlldata\", SomeColumns(\"id\", \"date\", \"batchtime\", \"batchwindow\", \"totalinwindow\", \"uniqueperbatch\", \"hllstore\"))\n\n      }\n    })\n\n\n    ssc.start()\n    ssc.awaitTerminationOrTimeout(minutesToStream * 60  * 1000)//2 minutes...\n    ssc.stop(stopSparkContext \u003d false, stopGracefully\u003dtrue)\n    \n",
      "user": "anonymous",
      "dateUpdated": "Oct 30, 2017 10:20:27 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 1656.0,
              "optionOpen": false
            }
          }
        },
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508869186050_-1220730212",
      "id": "20171024-141946_1818057078",
      "dateCreated": "Oct 24, 2017 2:19:46 PM",
      "dateStarted": "Oct 30, 2017 10:19:58 PM",
      "dateFinished": "Oct 30, 2017 10:30:30 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\nimport com.datastax.spark.connector.streaming._\nimport com.datastax.spark.connector._\nimport com.datastax.spark.connector.SomeColumns\nimport com.datastax.spark.connector.rdd._\nimport org.apache.spark.SparkContext    \nimport org.apache.spark.SparkContext._\nimport org.apache.spark.SparkConf\nimport org.apache.spark.storage.StorageLevel\nimport org.apache.spark.streaming.{Seconds, StreamingContext}\n\nimport com.twitter.algebird.HyperLogLog._\nimport com.twitter.algebird.HyperLogLogMonoid\nimport org.apache.log4j.{Level, Logger}\nimport com.twitter.algebird.HLL\nimport java.util.Date\nimport java.text.SimpleDateFormat\n\nval todayAsString \u003d new SimpleDateFormat(\"MM-dd-yyyy\").format(new Date())\n   \nval rdd  \u003d sc.cassandraTable[Array[Byte]](\"approximations\", \"hlldata\")\n              .select(\"hllstore\")\n              .where(\"id \u003d ?\", \"tweets\").where(\"date \u003d ?\", todayAsString)\n\nval approxUsers \u003d rdd.mapPartitions(ids \u003d\u003e {\n  ids.map(id \u003d\u003e fromBytes(id))\n}).reduce(_ + _)\n\nval hllagg \u003d approxUsers.estimatedSize.toInt\n\nprintln(\"Total For HLL:\"+hllagg)\n\n",
      "user": "anonymous",
      "dateUpdated": "Oct 30, 2017 10:41:05 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1509047873901_-397627896",
      "id": "20171026-155753_802562419",
      "dateCreated": "Oct 26, 2017 3:57:53 PM",
      "dateStarted": "Oct 30, 2017 10:41:05 PM",
      "dateFinished": "Oct 30, 2017 10:41:09 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%cassandra\n\nSELECT * FROM approximations.hlldata WHERE id \u003d \u0027tweets\u0027 ALLOW FILTERING;",
      "user": "anonymous",
      "dateUpdated": "Oct 30, 2017 10:22:29 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {
          "0": {
            "graph": {
              "mode": "multiBarChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "lineChart": {},
                "stackedAreaChart": {
                  "style": "stack"
                },
                "multiBarChart": {}
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "batchtime",
                  "index": 2.0,
                  "aggr": "sum"
                },
                {
                  "name": "id",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "uniqueperbatch",
                  "index": 6.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/undefined"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508888237215_947822464",
      "id": "20171024-193717_1816755798",
      "dateCreated": "Oct 24, 2017 7:37:17 PM",
      "dateStarted": "Oct 30, 2017 10:22:29 PM",
      "dateFinished": "Oct 30, 2017 10:22:29 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "user": "anonymous",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508870408928_-354877741",
      "id": "20171024-144008_2052649078",
      "dateCreated": "Oct 24, 2017 2:40:08 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "DataStax Sketches/HyperLogLog",
  "id": "2CX4D919U",
  "angularObjects": {
    "2CYQJDWVR:shared_process": [],
    "2CX4XD82R:shared_process": [],
    "2CX8KQKX6:shared_process": [],
    "2CX8NHPMT:shared_process": [],
    "2CXZ4DJ9D:shared_process": [],
    "2CVZVC78P:shared_process": [],
    "2CVCKC261:shared_process": [],
    "2CVN8SZ2K:shared_process": [],
    "2CX22KWY9:shared_process": [],
    "2CY63N5YW:shared_process": [],
    "2CWD6KZ4F:shared_process": [],
    "2CW1XE6V5:shared_process": [],
    "2CYXXU57D:shared_process": [],
    "2CYFA5J4Y:shared_process": [],
    "2CZ8799S8:shared_process": [],
    "2CVNMGNH2:shared_process": [],
    "2CWVZ86QG:shared_process": [],
    "2CXAV6KVC:shared_process": [],
    "2CVJFFRZ7:shared_process": []
  },
  "config": {},
  "info": {}
}